{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOLf+xjlRVZegRcCvy4dQ6u",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Saswata020/Deep_learning_Concept/blob/main/Image_Classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Structure of an Image Classification Task\n",
        "* **Image Preprocessing** - The aim of this process is to improve the image data(features) by *suppressing unwanted distortions* and *enhancement of some important image features* so that our Computer Vision models can benefit from this improved data to work on.\n",
        "\n",
        "* **Detection of an object** - Detection refers to the localization of an object which *means the segmentation of the image and identifying the position of the object of interest*.\n",
        "* **Feature extraction and Training**- This is a crucial step wherein statistical or deep learning methods are used to identify the most *interesting patterns of the image, features that might be unique to a particular class and that will, later on, help the model to differentiate between different classes.* This process where the model learns the features from the dataset is called model training.\n",
        "* **Classification of the object** - This step categorizes detected objects into predefined classes by using a suitable classification technique that compares the image patterns with the target patterns."
      ],
      "metadata": {
        "id": "8uAYROp4lGId"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Need for Image-Preprocessing\n",
        "Computers are able to perform computations on numbers and *is unable to interpret images in the way that we do*. We have to **somehow convert the images to numbers for the computer to understand**.\n",
        "The aim of pre-processing is an improvement of the image data that **suppresses unwilling distortions or enhances some image features important for further processing**."
      ],
      "metadata": {
        "id": "I0De_TVZmKt2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Steps for image pre-processing:\n",
        "\n",
        "* Read image\n",
        "* Resize image\n",
        "* Data Augmentation\n",
        "* Gray scaling of image\n",
        "* Reflection\n",
        "* Gaussian Blurring\n",
        "* Histogram Equalization\n",
        "* Rotation\n",
        "* Translation\n"
      ],
      "metadata": {
        "id": "lP5WA1LynMu7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Reading Image\n",
        "In this step, we simply store the path to our image dataset into a variable and then we create a function to load folders containing images into arrays so that computers can deal with it."
      ],
      "metadata": {
        "id": "n34oGR3Wnr8j"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "nvw8eG5RlBmn"
      },
      "outputs": [],
      "source": [
        "# importing libraries\n",
        "from pathlib import Path  # Import the Path class from pathlib for working with file paths\n",
        "import glob  # Import the glob module for file pattern matching\n",
        "import pandas as pd  # Import the pandas library for data manipulation\n",
        "\n",
        "# reading images from path\n",
        "images_dir = Path('img')  # Set the 'images_dir' variable to the 'img' directory using Path\n",
        "\n",
        "images = images_dir.glob(\"*.tif\")  # Use glob to get a list of all files with '.tif' extension in 'img' directory\n",
        "\n",
        "train_data = []  # Initialize an empty list 'train_data' to store image filenames and labels\n",
        "\n",
        "counter = 0  # Initialize a counter variable to keep track of the number of processed images\n",
        "\n",
        "# Iterate through the images in the 'images' generator\n",
        "for img in images:\n",
        "    counter += 1  # Increment the counter by 1 for each image processed\n",
        "\n",
        "    # Check if the counter is less than or equal to 130\n",
        "    if counter <= 130:\n",
        "        train_data.append((img, 1))  # Append a tuple (img, 1) to 'train_data' with label 1\n",
        "    else:\n",
        "        train_data.append((img, 0))  # Append a tuple (img, 0) to 'train_data' with label 0\n",
        "\n",
        "# converting data into pandas dataframe for easy visualization\n",
        "train_data = pd.DataFrame(train_data, columns=['image', 'label'], index=None)  # Convert 'train_data' list to a DataFrame\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Resize image\n",
        "Some images captured by a camera and fed to our AI algorithm vary in size, therefore, we should establish a base size for all images fed into our AI algorithms by resizing them.\n",
        "\n",
        "* Sample code for resizing images into 229x229 dimensions:"
      ],
      "metadata": {
        "id": "gyhMUkyyo2x6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "# Iterate through the images in the 'images' generator\n",
        "for img_path in images:\n",
        "    counter += 1  # Increment the counter by 1 for each image processed\n",
        "\n",
        "    # Read the image using OpenCV\n",
        "    img = cv2.imread(str(img_path))\n",
        "\n",
        "    # Check if the counter is less than or equal to 130\n",
        "    if counter <= 130:\n",
        "        img = cv2.resize(img, (229, 229))  # Resize the image\n",
        "        train_data.append((img, 1))  # Append a tuple (img, 1) to 'train_data' with label 1\n",
        "    else:\n",
        "        train_data.append((img, 0))  # Append a tuple (img, 0) to 'train_data' with label 0\n",
        "\n",
        "# converting data into pandas dataframe for easy visualization\n",
        "train_data = pd.DataFrame(train_data, columns=['image', 'label'], index=None)  # Convert 'train_data' list to a DataFrame\n"
      ],
      "metadata": {
        "id": "woyefmjznxQQ"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Data Augmentation\n",
        "Data augmentation is a way of creating new 'data' with different orientations. The benefits of this are two-fold, the first being the ability to generate 'more data' from limited data and secondly, it prevents overfitting."
      ],
      "metadata": {
        "id": "0DIbNp47qXHh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Image\n",
        "# URL of the image\n",
        "image_url = \"https://iq.opengenus.org/content/images/2019/07/cat_aug.png\"\n",
        "# Display the image\n",
        "Image(url=image_url)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 377
        },
        "id": "JsejWFR6pXMv",
        "outputId": "cc712eea-12a6-4fe8-cca4-6dc37cdc9894"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<img src=\"https://iq.opengenus.org/content/images/2019/07/cat_aug.png\"/>"
            ],
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Data Augmentation Techniques:\n",
        "\n",
        "**Gray Scaling**\n",
        "\n",
        "The image will be *converted to gray scale* *(range of gray shades from white to black)* the *computer will assign each pixel a value based on how dark it is*. All the *numbers are put into an array* and the computer does computations on that array.\n",
        "\n",
        "Sample code to convert an RGB(3 channels) image into a Gray scale image:"
      ],
      "metadata": {
        "id": "-uGOgQAbq34a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "\n",
        "# Iterate through the images in the 'images' generator\n",
        "for img_path in images:\n",
        "    counter += 1  # Increment the counter by 1 for each image processed\n",
        "\n",
        "    # Read the image using OpenCV\n",
        "    img = cv2.imread(str(img_path))\n",
        "\n",
        "    # Check if the counter is less than or equal to 130\n",
        "    if counter <= 130:\n",
        "        img = cv2.resize(img, (229, 229))  # Resize the image\n",
        "        train_data.append((img, 1))  # Append a tuple (img, 1) to 'train_data' with label 1\n",
        "    else:\n",
        "        train_data.append((img, 0))  # Append a tuple (img, 0) to 'train_data' with label 0\n",
        "\n",
        "    # Convert the current image to grayscale\n",
        "    img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "# converting data into pandas dataframe for easy visualization\n",
        "train_data = pd.DataFrame(train_data, columns=['image', 'label'], index=None)  # Convert 'train_data' list to a DataFrame\n"
      ],
      "metadata": {
        "id": "bEx_WPvRquyJ"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_url = \"https://iq.opengenus.org/content/images/2019/07/rgb.jpg\"\n",
        "# Display the image\n",
        "Image(url=image_url)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 252
        },
        "id": "Zo4OC093rXoQ",
        "outputId": "660ff76e-afa9-4249-b5a5-8f47e1335fc6"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<img src=\"https://iq.opengenus.org/content/images/2019/07/rgb.jpg\"/>"
            ],
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "image_url = \"https://iq.opengenus.org/content/images/2019/07/grayscale.jpg\"\n",
        "# Display the image\n",
        "Image(url=image_url)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 232
        },
        "id": "A80Kc7dZr6MG",
        "outputId": "dcd11b8a-8af6-4c30-aff5-febe219cb63b"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<img src=\"https://iq.opengenus.org/content/images/2019/07/grayscale.jpg\"/>"
            ],
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Reflection/Flip\n",
        "\n",
        "You can **flip images horizontally and vertically**. Some frameworks do not provide function for vertical flips. But, a vertical flip is equivalent to rotating an image by 180 degrees and then performing a horizontal flip."
      ],
      "metadata": {
        "id": "21fz7ISXsHyE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "import glob\n",
        "\n",
        "# Set the 'images_dir' variable to the 'img' directory using Path\n",
        "images_dir = Path('img')\n",
        "\n",
        "# Use glob to get a list of all files with '.tif' extension in 'img' directory\n",
        "images = images_dir.glob(\"*.tif\")\n",
        "\n",
        "train_data = []  # Initialize an empty list 'train_data' to store image filenames and labels\n",
        "counter = 0  # Initialize a counter variable to keep track of the number of processed images\n",
        "\n",
        "# Iterate through the images in the 'images' generator\n",
        "for img_path in images:\n",
        "    counter += 1  # Increment the counter by 1 for each image processed\n",
        "\n",
        "    # Read the image using OpenCV\n",
        "    img = cv2.imread(str(img_path))\n",
        "\n",
        "    # Check if the counter is less than or equal to 130\n",
        "    if counter <= 130:\n",
        "        img = cv2.resize(img, (229, 229))  # Resize the image\n",
        "        train_data.append((img, 1))  # Append a tuple (img, 1) to 'train_data' with label 1\n",
        "    else:\n",
        "        train_data.append((img, 0))  # Append a tuple (img, 0) to 'train_data' with label 0\n",
        "\n",
        "    # Convert the current image to grayscale\n",
        "    img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Horizontal Flip\n",
        "    img_horizontal = cv2.flip(img_gray, 0)  # Horizontal flip\n",
        "\n",
        "    # Vertical Flip\n",
        "    img_vertical = cv2.flip(img_gray, 1)  # Vertical flip\n",
        "\n",
        "    # Append horizontally flipped image with label 1 (you can change label as needed)\n",
        "    train_data.append((img_horizontal, 1))\n",
        "\n",
        "    # Append vertically flipped image with label 1 (you can change label as needed)\n",
        "    train_data.append((img_vertical, 1))\n",
        "\n",
        "# Convert 'train_data' list to a DataFrame\n",
        "train_data = pd.DataFrame(train_data, columns=['image', 'label'], index=None)\n"
      ],
      "metadata": {
        "id": "hvLiTHMYsCWJ"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Gaussian Blurring\n",
        "\n",
        "Gaussian blur (also known as Gaussian smoothing) is the **result of blurring an image by a Gaussian function**. It is a widely used effect in graphics software, typically to **reduce image noise**."
      ],
      "metadata": {
        "id": "qP-cc27ksxJM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "from scipy import ndimage  # Importing the ndimage module from SciPy\n",
        "import glob\n",
        "\n",
        "# Set the 'images_dir' variable to the 'img' directory using Path\n",
        "images_dir = Path('img')\n",
        "\n",
        "# Use glob to get a list of all files with '.tif' extension in 'img' directory\n",
        "images = images_dir.glob(\"*.tif\")\n",
        "\n",
        "train_data = []  # Initialize an empty list 'train_data' to store image filenames and labels\n",
        "counter = 0  # Initialize a counter variable to keep track of the number of processed images\n",
        "\n",
        "# Iterate through the images in the 'images' generator\n",
        "for img_path in images:\n",
        "    counter += 1  # Increment the counter by 1 for each image processed\n",
        "\n",
        "    # Read the image using OpenCV\n",
        "    img = cv2.imread(str(img_path))\n",
        "\n",
        "    # Check if the counter is less than or equal to 130\n",
        "    if counter <= 130:\n",
        "        img = cv2.resize(img, (229, 229))  # Resize the image\n",
        "        train_data.append((img, 1))  # Append a tuple (img, 1) to 'train_data' with label 1\n",
        "    else:\n",
        "        train_data.append((img, 0))  # Append a tuple (img, 0) to 'train_data' with label 0\n",
        "\n",
        "    # Convert the current image to grayscale\n",
        "    img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Apply Gaussian filter to the grayscale image\n",
        "    img_filtered = ndimage.gaussian_filter(img_gray, sigma=5.11) #Image with blur radius = 5.1\n",
        "\n",
        "    # Horizontal Flip\n",
        "    img_horizontal = cv2.flip(img_filtered, 0)  # Horizontal flip\n",
        "\n",
        "    # Vertical Flip\n",
        "    img_vertical = cv2.flip(img_filtered, 1)  # Vertical flip\n",
        "\n",
        "    # Append horizontally flipped and filtered image with label 1 (you can change label as needed)\n",
        "    train_data.append((img_horizontal, 1))\n",
        "\n",
        "    # Append vertically flipped and filtered image with label 1 (you can change label as needed)\n",
        "    train_data.append((img_vertical, 1))\n",
        "\n",
        "# Convert 'train_data' list to a DataFrame\n",
        "train_data = pd.DataFrame(train_data, columns=['image', 'label'], index=None)\n"
      ],
      "metadata": {
        "id": "hXN0uvfcsmjZ"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Histogram Equalization\n",
        "\n",
        "Histogram equalization is another image processing technique to **increase global contrast of an image using the image intensity histogram**. This method needs no parameter, but it sometimes results in an unnatural looking image."
      ],
      "metadata": {
        "id": "n6BzcuprtfNK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "image_url = \"https://iq.opengenus.org/content/images/2019/07/histogram.jpeg\"\n",
        "# Display the image\n",
        "Image(url=image_url)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "UyfcWWles90U",
        "outputId": "3187c431-f65e-4461-ee1a-c93e7eb0775e"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<img src=\"https://iq.opengenus.org/content/images/2019/07/histogram.jpeg\"/>"
            ],
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "from scipy import ndimage\n",
        "import glob\n",
        "\n",
        "# Define the histogram equalization function\n",
        "def hist(img):\n",
        "    img_to_yuv = cv2.cvtColor(img, cv2.COLOR_BGR2YUV)\n",
        "    img_to_yuv[:, :, 0] = cv2.equalizeHist(img_to_yuv[:, :, 0])\n",
        "    hist_equalization_result = cv2.cvtColor(img_to_yuv, cv2.COLOR_YUV2BGR)\n",
        "    return hist_equalization_result\n",
        "\n",
        "# Set the 'images_dir' variable to the 'img' directory using Path\n",
        "images_dir = Path('img')\n",
        "\n",
        "# Use glob to get a list of all files with '.tif' extension in 'img' directory\n",
        "images = images_dir.glob(\"*.tif\")\n",
        "\n",
        "train_data = []  # Initialize an empty list 'train_data' to store image filenames and labels\n",
        "counter = 0  # Initialize a counter variable to keep track of the number of processed images\n",
        "\n",
        "# Iterate through the images in the 'images' generator\n",
        "for img_path in images:\n",
        "    counter += 1  # Increment the counter by 1 for each image processed\n",
        "\n",
        "    # Read the image using OpenCV\n",
        "    img = cv2.imread(str(img_path))\n",
        "\n",
        "    # Check if the counter is less than or equal to 130\n",
        "    if counter <= 130:\n",
        "        img = cv2.resize(img, (229, 229))  # Resize the image\n",
        "        train_data.append((img, 1))  # Append a tuple (img, 1) to 'train_data' with label 1\n",
        "    else:\n",
        "        train_data.append((img, 0))  # Append a tuple (img, 0) to 'train_data' with label 0\n",
        "\n",
        "    # Apply histogram equalization to the current image\n",
        "    img_equalized = hist(img)\n",
        "\n",
        "    # Convert the current image to grayscale\n",
        "    img_gray = cv2.cvtColor(img_equalized, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Apply Gaussian filter to the grayscale image\n",
        "    img_filtered = ndimage.gaussian_filter(img_gray, sigma=5.11)\n",
        "\n",
        "    # Horizontal Flip\n",
        "    img_horizontal = cv2.flip(img_filtered, 0)  # Horizontal flip\n",
        "\n",
        "    # Vertical Flip\n",
        "    img_vertical = cv2.flip(img_filtered, 1)  # Vertical flip\n",
        "\n",
        "    # Append horizontally flipped and filtered image with label 1 (you can change label as needed)\n",
        "    train_data.append((img_horizontal, 1))\n",
        "\n",
        "    # Append vertically flipped and filtered image with label 1 (you can change label as needed)\n",
        "    train_data.append((img_vertical, 1))\n",
        "\n",
        "# Convert 'train_data' list to a DataFrame\n",
        "train_data = pd.DataFrame(train_data, columns=['image', 'label'], index=None)\n"
      ],
      "metadata": {
        "id": "GURRWvg9ty-J"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Rotation\n",
        "\n",
        "This is yet another **image augmentation technique**. Rotating an *image might not preserve its original dimensions* (depending on what angle you choose to rotate it with )"
      ],
      "metadata": {
        "id": "ot6FttWfu9sz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "from scipy import ndimage\n",
        "import glob\n",
        "import random  # Import the random module for random rotation\n",
        "\n",
        "# Define the histogram equalization function\n",
        "def hist(img):\n",
        "    img_to_yuv = cv2.cvtColor(img, cv2.COLOR_BGR2YUV)\n",
        "    img_to_yuv[:, :, 0] = cv2.equalizeHist(img_to_yuv[:, :, 0])\n",
        "    hist_equalization_result = cv2.cvtColor(img_to_yuv, cv2.COLOR_YUV2BGR)\n",
        "    return hist_equalization_result\n",
        "\n",
        "# Define the rotation function\n",
        "def rotation(img):\n",
        "    rows, cols = img.shape[0], img.shape[1]\n",
        "    randDeg = random.randint(-180, 180)\n",
        "    matrix = cv2.getRotationMatrix2D((cols / 2, rows / 2), randDeg, 0.70)\n",
        "    rotated = cv2.warpAffine(img, matrix, (cols, rows), borderMode=cv2.BORDER_CONSTANT, borderValue=(144, 159, 162))\n",
        "    return rotated\n",
        "\n",
        "# Set the 'images_dir' variable to the 'img' directory using Path\n",
        "images_dir = Path('img')\n",
        "\n",
        "# Use glob to get a list of all files with '.tif' extension in 'img' directory\n",
        "images = images_dir.glob(\"*.tif\")\n",
        "\n",
        "train_data = []  # Initialize an empty list 'train_data' to store image filenames and labels\n",
        "counter = 0  # Initialize a counter variable to keep track of the number of processed images\n",
        "\n",
        "# Iterate through the images in the 'images' generator\n",
        "for img_path in images:\n",
        "    counter += 1  # Increment the counter by 1 for each image processed\n",
        "\n",
        "    # Read the image using OpenCV\n",
        "    img = cv2.imread(str(img_path))\n",
        "\n",
        "    # Check if the counter is less than or equal to 130\n",
        "    if counter <= 130:\n",
        "        img = cv2.resize(img, (229, 229))  # Resize the image\n",
        "        train_data.append((img, 1))  # Append a tuple (img, 1) to 'train_data' with label 1\n",
        "    else:\n",
        "        train_data.append((img, 0))  # Append a tuple (img, 0) to 'train_data' with label 0\n",
        "\n",
        "    # Apply histogram equalization to the current image\n",
        "    img_equalized = hist(img)\n",
        "\n",
        "    # Convert the current image to grayscale\n",
        "    img_gray = cv2.cvtColor(img_equalized, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Apply Gaussian filter to the grayscale image\n",
        "    img_filtered = ndimage.gaussian_filter(img_gray, sigma=5.11)\n",
        "\n",
        "    # Horizontal Flip\n",
        "    img_horizontal = cv2.flip(img_filtered, 0)  # Horizontal flip\n",
        "\n",
        "    # Vertical Flip\n",
        "    img_vertical = cv2.flip(img_filtered, 1)  # Vertical flip\n",
        "\n",
        "    # Append horizontally flipped and filtered image with label 1 (you can change label as needed)\n",
        "    train_data.append((img_horizontal, 1))\n",
        "\n",
        "    # Append vertically flipped and filtered image with label 1 (you can change label as needed)\n",
        "    train_data.append((img_vertical, 1))\n",
        "\n",
        "    # Apply random rotation to the image\n",
        "    img_rotated = rotation(img_filtered)\n",
        "\n",
        "    # Append rotated and filtered image with label 1 (you can change label as needed)\n",
        "    train_data.append((img_rotated, 1))\n",
        "\n",
        "# Convert 'train_data' list to a DataFrame\n",
        "train_data = pd.DataFrame(train_data, columns=['image', 'label'], index=None)\n"
      ],
      "metadata": {
        "id": "hKZZ_NWOt6_T"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_url = \"https://iq.opengenus.org/content/images/2019/07/rot.jpeg\"\n",
        "# Display the image\n",
        "Image(url=image_url)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        },
        "id": "WlIYwarxviZK",
        "outputId": "322cfc6a-caf9-4c2d-ae01-48f5ed8f9792"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<img src=\"https://iq.opengenus.org/content/images/2019/07/rot.jpeg\"/>"
            ],
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Translation\n",
        "\n",
        "Translation just involves **moving the image along the X or Y direction (or both)**.\n",
        "This method of augmentation is very **useful as most objects can be located at almost anywhere in the image**. This forces **our feature extractor to look everywhere**."
      ],
      "metadata": {
        "id": "p7_QVeCqvvy-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "from scipy import ndimage\n",
        "import glob\n",
        "import random  # Import the random module for random rotation\n",
        "import numpy as np  # Import NumPy for array operations\n",
        "\n",
        "# Define the histogram equalization function\n",
        "def hist(img):\n",
        "    img_to_yuv = cv2.cvtColor(img, cv2.COLOR_BGR2YUV)\n",
        "    img_to_yuv[:, :, 0] = cv2.equalizeHist(img_to_yuv[:, :, 0])\n",
        "    hist_equalization_result = cv2.cvtColor(img_to_yuv, cv2.COLOR_YUV2BGR)\n",
        "    return hist_equalization_result\n",
        "\n",
        "# Define the rotation function\n",
        "def rotation(img):\n",
        "    rows, cols = img.shape[0], img.shape[1]\n",
        "    randDeg = random.randint(-180, 180)\n",
        "    matrix = cv2.getRotationMatrix2D((cols / 2, rows / 2), randDeg, 0.70)\n",
        "    rotated = cv2.warpAffine(img, matrix, (cols, rows), borderMode=cv2.BORDER_CONSTANT, borderValue=(144, 159, 162))\n",
        "    return rotated\n",
        "\n",
        "# Set the 'images_dir' variable to the 'img' directory using Path\n",
        "images_dir = Path('img')\n",
        "\n",
        "# Use glob to get a list of all files with '.tif' extension in 'img' directory\n",
        "images = images_dir.glob(\"*.tif\")\n",
        "\n",
        "train_data = []  # Initialize an empty list 'train_data' to store image filenames and labels\n",
        "counter = 0  # Initialize a counter variable to keep track of the number of processed images\n",
        "\n",
        "# Iterate through the images in the 'images' generator\n",
        "for img_path in images:\n",
        "    counter += 1  # Increment the counter by 1 for each image processed\n",
        "\n",
        "    # Read the image using OpenCV\n",
        "    img = cv2.imread(str(img_path))\n",
        "\n",
        "    # Check if the counter is less than or equal to 130\n",
        "    if counter <= 130:\n",
        "        img = cv2.resize(img, (229, 229))  # Resize the image\n",
        "        train_data.append((img, 1))  # Append a tuple (img, 1) to 'train_data' with label 1\n",
        "    else:\n",
        "        train_data.append((img, 0))  # Append a tuple (img, 0) to 'train_data' with label 0\n",
        "\n",
        "    # Apply histogram equalization to the current image\n",
        "    img_equalized = hist(img)\n",
        "\n",
        "    # Convert the current image to grayscale\n",
        "    img_gray = cv2.cvtColor(img_equalized, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Apply Gaussian filter to the grayscale image\n",
        "    img_filtered = ndimage.gaussian_filter(img_gray, sigma=5.11)\n",
        "\n",
        "    # Horizontal Flip\n",
        "    img_horizontal = cv2.flip(img_filtered, 0)  # Horizontal flip\n",
        "\n",
        "    # Vertical Flip\n",
        "    img_vertical = cv2.flip(img_filtered, 1)  # Vertical flip\n",
        "\n",
        "    # Append horizontally flipped and filtered image with label 1 (you can change label as needed)\n",
        "    train_data.append((img_horizontal, 1))\n",
        "\n",
        "    # Append vertically flipped and filtered image with label 1 (you can change label as needed)\n",
        "    train_data.append((img_vertical, 1))\n",
        "\n",
        "    # Apply random rotation to the image\n",
        "    img_rotated = rotation(img_filtered)\n",
        "\n",
        "    # Append rotated and filtered image with label 1 (you can change label as needed)\n",
        "    train_data.append((img_rotated, 1))\n",
        "\n",
        "    # Apply translation to the image\n",
        "    img_translated = cv2.warpAffine(img_filtered, np.float32([[1, 0, 84], [0, 1, 56]]), (img.shape[1], img.shape[0]),\n",
        "                                     borderMode=cv2.BORDER_CONSTANT, borderValue=(144, 159, 162))\n",
        "\n",
        "    # Append translated and filtered image with label 1 (you can change label as needed)\n",
        "    train_data.append((img_translated, 1))\n",
        "\n",
        "# Convert 'train_data' list to a DataFrame\n",
        "train_data = pd.DataFrame(train_data, columns=['image', 'label'], index=None)\n"
      ],
      "metadata": {
        "id": "gATTDWxsvou2"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_url = \"https://iq.opengenus.org/content/images/2019/07/trans.png\"\n",
        "# Display the image\n",
        "Image(url=image_url)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "r51v1IQzwQ2i",
        "outputId": "6b532a93-f4b0-4bd9-b438-d7cb38882e61"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<img src=\"https://iq.opengenus.org/content/images/2019/07/trans.png\"/>"
            ],
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Hj9BwjuTwdrj"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}